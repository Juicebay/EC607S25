---
title: "Problem Set 2"
format:
  html:
    theme: cosmo
    toc: true
    number-sections: true
    self-contained: true
---

## General regression analysis and the CIA

**01** Loading packages...

```{r, setup}
# Packages
pacman::p_load(ggplot2, scales, fastverse, fixest, here)
# Load data
ps_dt = here('data-002.csv') %>% fread()
```

**02** Time for some figures.

```{r, figures}
# Histogram: income gap, 2010
ggplot(
  data = ps_dt,
  aes(x = income_white_2010 - income_black_2010, fill = as.factor(had_rosenwald_school))
) +
geom_histogram(alpha = 0.8, color = NA, position = 'identity', bins = 50) +
scale_fill_viridis_d('Had Rosenwald School', labels = c('N', 'Y')) +
scale_x_continuous('Income Gap in 2010', labels = dollar) +
scale_y_continuous('Count', labels = comma) +
theme_minimal() +
theme(legend.position = 'bottom')
# Histogram: pct pop enslaved, 2010
ggplot(
  data = ps_dt,
  aes(x = pct_pop_enslaved_1860/100, fill = as.factor(had_rosenwald_school))
) +
geom_histogram(alpha = 0.8, color = NA, position = 'identity', bins = 50) +
scale_fill_viridis_d('Had Rosenwald School', labels = c('N', 'Y')) +
scale_x_continuous('Percent of Population Enslaved in 1860', labels = percent) +
scale_y_continuous('Count', labels = comma) +
theme_minimal() +
theme(legend.position = 'bottom')
# Scatter plot: income and pct pop enslaved 
ggplot(
  data = ps_dt,
  aes(x = pct_pop_enslaved_1860/100, y = income_white_2010 - income_black_2010, color = as.factor(had_rosenwald_school))
) +
geom_point(alpha = 0.8) +
scale_color_viridis_d('Had Rosenwald School', labels = c('N', 'Y')) +
scale_x_continuous('Percent of Population Enslaved in 1860', labels = percent) +
scale_y_continuous('Income Gap in 2010', labels = dollar) +
theme_minimal() +
theme(legend.position = 'bottom')
```

**03** Regressing the income gap on the indicator for Rosenwald school, we are assuming that schools' locations are as good as random (in their distribution across counties). In other words, we need anything that affects the gap—other than the schools—to be independent of whether counties had Rosenwald schools.

```{r, answer-03}
# Cross-sectional regression
reg03 = feols(
  income_white_2010 - income_black_2010 ~ 
  had_rosenwald_school,
  data = ps_dt
)
etable(reg03)
```

**04** Estimates below. Our CIA updates to *within state* placement of schools needs to be as good as random (conditional on state, all non-Rosenwald school determinants of the income gap are independent of whether or not a county had a Rosenwald school).

```{r, answer-04}
# Add state fixed effects
reg04 = feols(
  income_white_2010 - income_black_2010 ~ 
  had_rosenwald_school | 
  state,
  data = ps_dt
)
etable(reg04)
```

**05** Estimates below...

```{r, answer-05}
# Add 1860 controls
reg05 = feols(
  income_white_2010 - income_black_2010 ~ 
  had_rosenwald_school + pct_pop_enslaved_1860 + pop_total_1860 | 
  state,
  data = ps_dt
)
etable(reg05)
```

**06** Comparison below. Yes, the movement in the point estimate for the effect of Rosenwald schools seems to match what we would expect. One would like expect that places with more histories of more intense slavery would have larger income gaps today and would also have been more likely to receive a Rosenwald school. When we control for the county's history of slavery (and total population in 1860), we see the coefficient on the Rosenwald school indicator decrease.

```{r, answer-06}
etable(reg04, reg05)
```

**07** Open answer: Just want to see a DAG that makes the point that we have likely not controlled for everything.

**08** I'd be concerned that there could be a bad-controls issue here: if the schools affected current (or 2010) population levels, then we should not control for it. If we don't think schools affected current population, then we are probably fine (depending on the DAG you have in mind).

## Matching

**09** The histogram of treated units' distances to their nearest control unit (note: I'm using log~10~ for the *x* axis).

```{r, answer-09}
# Load MatchIt
pacman::p_load(MatchIt)
# Find distances between treated and control observations
dist_mat = mahalanobis_dist(
  formula = had_rosenwald_school ~ pct_pop_enslaved_1860 + pop_total_1860,
  data = ps_dt,
)
# Find the minimum distance from each treated individual (rows) to the controls (columns)
trt_dist = apply(X = dist_mat, FUN = min, MARGIN = 1)
# Make the histogram
ggplot(
  data = data.table(dist = trt_dist),
  aes(x = dist)
) +
geom_histogram(alpha = 0.8, fill = viridis::viridis(1), color = NA, position = 'identity', binwidth = 0.1) +
scale_x_log10(bquote(Mahalanobis~distance~(log[10]~scale))) +
scale_y_continuous('Count', labels = comma) +
theme_minimal() 
```

**10** 

```{r, answer10}
# Match each treated unit to its control unit
# Step 1: Find the index of the control units that match to each treated unit
ctrl_j = apply(X = dist_mat, FUN = which.min, MARGIN = 1)
# Step 2: Find the control units (rows) implied by the indices
ctrl_r = colnames(dist_mat)[ctrl_j] |> as.numeric()
# Step 3: Create a dataset of treated individuals and their nearest neighbors
match_dt = data.table(
  income_gap_trt = ps_dt[had_rosenwald_school == 1, income_white_2010 - income_black_2010],
  income_gap_ctrl = ps_dt[ctrl_r, income_white_2010 - income_black_2010]
)
# Step 4: Calculate the differences
match_dt[, trt_effect := income_gap_trt - income_gap_ctrl]
# Plot a histogram of the individual treatment effects
ggplot(
  data = match_dt,
  aes(x = trt_effect)
) +
geom_histogram(alpha = 0.8, fill = viridis::viridis(1), color = NA, position = 'identity', bins = 50) +
geom_vline(xintercept = match_dt[,mean(trt_effect)], color = 'orange') + 
scale_x_continuous('Estimated effect of Rosenwald school on the income gap', labels = dollar) +
scale_y_continuous('Count', labels = comma) +
theme_minimal() 
```

The estimate for the average treatment effect is approximately `r match_dt[, mean(trt_effect) |> dollar()]`.

**11** The estimate is much smaller and no longer signficantly different from zero.

**12** The estimator in **10** is estimating the average treatment effect on the treated (ATET or ATT), because we've effectively conditioned on treated counties—we're only matching control counties to treated counties.

*Note* The average effect here is at the count level. If we wanted an average effect at the individual level, we would want to weight by population (above, I've treated all counties as equal when taking the mean).

## Propensity-score methods

**13** Estimate the propensity scores...

```{r, answer-13}
# Estimate propensity scores as function of 1860 attributes
pscore_reg = feglm(
  had_rosenwald_school ~ 
  #pct_pop_enslaved_1860 + pop_total_1860,
  I(pct_pop_enslaved_1860^2) + I(pop_total_1860^2) + pct_pop_enslaved_1860 * pop_total_1860,
  data = ps_dt,
  family = 'logit'
)
# Add propensity scores to the dataset
ps_dt[, p_score := predict(pscore_reg, newdata = ps_dt)]
```

**14** Estimates below. The estimated effect of Rosenwald schools is smaller in magnitude and no longer significantly different from zero (still positive).

```{r, answer14}
# Estimate the 1860-controls regression, controlling for the propensity score
reg18 = feols(
  income_white_2010 - income_black_2010 ~ 
  had_rosenwald_school + pct_pop_enslaved_1860 + pop_total_1860 + p_score | 
  state,
  data = ps_dt
)
etable("OLS" = reg05, "Prop. Scores" = reg18)
```
**15** Checking overlap... doesn't look perfect (yet).

```{r, answer-15}
# Check overlap
ggplot(
  data = ps_dt,
  aes(x = p_score, fill = as.factor(had_rosenwald_school))
) +
geom_histogram(alpha = 0.8, color = NA, position = 'identity', binwidth = 0.01) +
scale_fill_viridis_d('Had Rosenwald School', labels = c('N', 'Y')) +
scale_x_continuous('Estimated Propensity Score', labels = percent) +
scale_y_continuous('Count', labels = comma) +
theme_minimal() +
theme(legend.position = 'bottom')
```

**16** Finding the violators.

```{r, answer-16}
# Enforce overlap
c_max = ps_dt[had_rosenwald_school == 0, max(p_score)]
t_min = ps_dt[had_rosenwald_school == 1, min(p_score)]
ps_dt[, overlap := 1]
ps_dt[had_rosenwald_school == 0 & p_score < t_min, overlap := 0]
ps_dt[had_rosenwald_school == 1 & p_score > c_max, overlap := 0]
```

Approximately `r ps_dt[, mean(overlap)] %>% percent(0.1)` of the observations comply with our enforced overlap.

**17** We need to be able to compare individuals with equal likelihoods of treatment. Without overlap, there is no counterfactual for some observations—and we cannot enforce the CIA.

**18** Enforcing overlap here doesn't actually change much...

```{r, answer-18}
# Repeat regression but now enforcing overlap
reg18 = feols(
  income_white_2010 - income_black_2010 ~ 
  had_rosenwald_school + pct_pop_enslaved_1860 + pop_total_1860 + p_score | 
  state,
  data = ps_dt[overlap == TRUE]
)
etable('No overlap' = reg18, 'Overlap' = reg18)
```

**19** The coefficient increases a bit when we inversely weight with the estimated propensity scores; it is marginally significant (at the 10% level).

```{r, }
# Add propensity score weights to the dataset
ps_dt[, p_weight := (
  had_rosenwald_school / p_score + (1 - had_rosenwald_school) / (1 - p_score)
)]
# Weighted regression (with controls; no propensity score)
reg15 = feols(
  income_white_2010 - income_black_2010 ~ 
  had_rosenwald_school + pct_pop_enslaved_1860 + pop_total_1860 | 
  state,
  weights = ~ p_weight,
  data = ps_dt[overlap == TRUE]
)
etable(reg15)
```

**20**

```{r, blocks}
# Estimate block-level treatement effects
block_dt = lapply(
  X = seq(0.4, 1, 0.1),
  FUN = function(b) {
    # The block's results
    b_est = feols(
      income_white_2010 - income_black_2010 ~ 
      had_rosenwald_school + pct_pop_enslaved_1860 + pop_total_1860 | state,
      data = ps_dt[overlap == TRUE & p_score > b - 0.1 & p_score <= b]
    )
    # Return 
    data.table(
      block = b,
      est =  as.matrix(b_est$coeftable)["had_rosenwald_school","Estimate"],
      n = b_est$nobs
    )
  }
) %>% rbindlist()
# Show block-level treatment effects
block_dt
# Estimate the average treatment effect
block_dt[, weighted.mean(x = est, w = n)]
```
